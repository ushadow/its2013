\documentclass{sigchi}

% Use this command to override the default ACM copyright statement (e.g. for preprints). 
% Consult the conference website for the camera-ready copyright statement.
\toappear{
  Submitted for review.
}

% Arabic page numbers for submission. 
% Remove this line to eliminate page numbers for the camera ready copy
\pagenumbering{arabic}


% Load basic packages
\usepackage{balance}  % to better equalize the last page
\usepackage{graphics} % for EPS, load graphicx instead
\usepackage{times}    % comment if you want LaTeX's default font
\usepackage{url}      % llt: nicely formatted URLs

% llt: Define a global style for URLs, rather that the default one
\makeatletter
\def\url@leostyle{%
  \@ifundefined{selectfont}{\def\UrlFont{\sf}}{\def\UrlFont{\small\bf\ttfamily}}}
\makeatother
\urlstyle{leo}


% To make various LaTeX processors do the right thing with page size.
\def\pprw{8.5in}
\def\pprh{11in}
\special{papersize=\pprw,\pprh}
\setlength{\paperwidth}{\pprw}
\setlength{\paperheight}{\pprh}
\setlength{\pdfpagewidth}{\pprw}
\setlength{\pdfpageheight}{\pprh}

% Make sure hyperref comes last of your loaded packages, 
% to give it a fighting chance of not being over-written, 
% since its job is to redefine many LaTeX commands.
\usepackage[pdftex]{hyperref}
\hypersetup{
pdftitle={SIGCHI Conference Proceedings Format},
pdfauthor={LaTeX},
pdfkeywords={SIGCHI, proceedings, archival format},
bookmarksnumbered,
pdfstartview={FitH},
colorlinks,
citecolor=black,
filecolor=black,
linkcolor=black,
urlcolor=black,
breaklinks=true,
}

% create a shortcut to typeset table headings
\newcommand\tabhead[1]{\small\textbf{#1}}


% End of preamble. Here it comes the document.
\begin{document}

\title{SIGCHI Conference Proceedings Format}

\numberofauthors{2}
\author{
  \alignauthor 1st Author Name\\
    \affaddr{Affiliation}\\
    \affaddr{Address}\\
    \email{e-mail address}\\
  \alignauthor 2nd Author Name\\
    \affaddr{Affiliation}\\
    \affaddr{Address}\\
    \email{e-mail address}\\
}

\maketitle

\begin{abstract}
In this paper we describe the formatting requirements for
SIGCHI Conference Proceedings, and this sample file
offers recommendations on writing for the worldwide
SIGCHI readership. Please review this document even if
you have submitted to SIGCHI conferences before, some
format details have changed relative to previous years.
\end{abstract}

\keywords{
  Guides; instructions; author's kit; conference publications;
  keywords should be separated by a semi-colon.
  \textcolor{red}{Mandatory section to be included in your final version.}
}

\category{H.5.m.}{Information Interfaces and Presentation (e.g. HCI)}{Miscellaneous}

See: \url{http://www.acm.org/about/class/1998/}
for more information and the full list of ACM classifiers
and descriptors. 
\textcolor{red}{Mandatory section to be included in your
final version. On the submission page only the classifiers'
letter-number combination will need to be entered.}

\section{Introduction}

Abstract Hidden Markov Model for online continuous gesture recognition with
unbounded and unsegmented RGB and depth video sequences. 

\section{Related Work}
Bag-of-feature approach is similar to the bag-of-word approach in document classification. 
To represent an image using BoW model, an image can be treated as a document. Similarly,
``words'' in images need to be identified too. To achieve this, it usually includes
following three steps: feature detection, feature description and code book generation~\cite{fei2005}.
In the bag-of-word approach for document classification, the notion of order of words is lost
~\cite{Russell2003}. Higher-order $n$-gram models maintain some local notion of word order.

Heng et al. did an evaluation of several feature detectors and descriptors for action
recognition in video sequences~\cite{wang2009}. They used the same bag-of-features SVM classification
method for all the feature detector and descriptor combinations. 
Codebook With the bag of words

SVM does not usually handle time series data. To use SVM for time series, one
can concatenate the input in a time series into one long vector sample. scale
short time 
action recognition

Any HHMM can be converted to regular HMM by creating an HMM state for every leaf in the HHMM
state transition diagram~\cite{murphy02}. Both HHMM and HMM have advantages and disadvantages. Advantages for HHMM
over a mixture of HMMs model.
\begin{itemize}
  \item Can share substructures ($S_t$) across different HMMs, but not in the mixture of HMMs model.
  \item HHMM can provide a mult-A flat HMM cannot easily provide 
\end{itemize}

Advantages of HMM
\begin{itemize}
  \item Can specify more constraints in the the parameters, i.e. use Bakis model. to reduce the total number of parameters
It is harder to impose Bakis model to HHMM since the hidden states are shared. The state transition probability for $S_t$ in HHMM
is $|S|^2 \times |G| $. In mixture HMMs model, it is $k\times |S|\times|G|$ where $k$ is the number of states a state can transit to. 
\end{itemize}

If we do not constrain the transition in the hidden states $S_t$, HHMM may have a fewer number of parameters because of the states sharing.
If we constrain the transition, specifying more structures in the sub HMMs, the mixture of HMMs can have fewer number of parameters.

Training HMMs separately and combining them into HHMM for gesture inference.

\subsection{Hand Tracking}
Marcos-Ramiro et al. ~\cite{marcos2013} develop a method of computing hand likelihood maps based on RGB videos. Optical flow
hands show more movement. Our method is very similar to their approach but we combine both RGB images and depth images to compute
the gesture salience map. They hypothesized that given a frontal, static camera pointing to the upper body of a person, hands are
normally the parts of the image that show more movement. The two strong indicators are: 

Space-time interest point
\section{Implementation Details}
PCA reduction. The features are in the PC space, so they should have small correlations.
So we set the covariance matrices for the Gaussian CPD to be diagonal.

Feature computation on video sequences can be broken down into two steps: 1)
locate points of interest by maximizing certain salience functions; 2) compute
feature descriptors to capture shape and motion in the neighborhoods of selected
points using image measurements such as spatial or spatio-temporal image
gradients and optical flow.

Local space-time features capture characteristic shape and motion in video and
provide relatively independent representation of events with respect to their
spatio-temporal shifts and scales. \cite{wang-spatio-2009}


\cite{wang-spatio-2009}
\subsection{Gesture Salience Detection}
Both the RGB camera and the depth camera can be noisy. RGB camera is sensitive to lighting conditions (cite)
Skin color: failure mode clothes with skin color.

We use a simple and off-the-shelf skin color detection method which is not trained on our data set to do a binary segmentation. The reason is
to make the method more generalizable. 1 iteration of Morphological close

compare to Kinect skeleton tracking (figure)

\subsection{HMM Training}

Compute termination probability $P(END|S_T)$

\begin{figure}[!h]
\centering
\includegraphics[width=0.9\columnwidth]{Figure1}
\caption{With Caption Below, be sure to have a good resolution image
  (see item D within the preparation instructions).}
\label{fig:figure1}
\end{figure}


\section{Experimental Evaluation}

\subsection{Data Set}
data set has both lighting conditions: normal and low intensity. IMU sensors, not used. Intrusive.

\subsection{Comparison of Feature Detection Methods}
% \begin{table}
%   \centering
%   \begin{tabular}{|c|c|c|}
%     \hline
%     \tabhead{Objects} &
%     \multicolumn{1}{|p{0.3\columnwidth}|}{\centering\tabhead{Caption --- pre-2002}} &
%     \multicolumn{1}{|p{0.4\columnwidth}|}{\centering\tabhead{Caption --- 2003 and afterwards}} \\
%     \hline
%     Tables & Above & Below \\
%     \hline
%     Figures & Below & Below \\
%     \hline
%   \end{tabular}
%   \caption{Table captions should be placed below the table.}
%   \label{tab:table1}
% \end{table}

\textbf{Dense} sampling extracts

Skin and skeleton method finds the skin contour 
  
We use the same feature descriptor 
\begin{table}
\centering
\begin{tabular}{|l|c|c|}
\hline
\tabhead{Feature detector} & {\tabhead{Accuracy}} & {\tabhead{F1}}\\
\hline
Dense sampling (full body) & & \\
\hline
Skin \& skeleton & & \\
\hline
Salience & & \\
\hline
\end{tabular}
\end{table}

\subsection{Comparison of Recognition Training Methods}
Graph search?
Same salience feature detector and descriptor.
\begin{table}
\centering
\begin{tabular}{|l|c|c|}
\hline
\tabhead{Training method} & {\tabhead{Accuracy}} & {\tabhead{F1}}\\
\hline
HMM & & \\
\hline
AHMM & & \\
\hline
AHMM fixed lag smoothing (L = 16) & & \\ 
\hline
\end{tabular}
\end{table}


\section{Future Work}
Do away from skin color, what if the user wear glove, or like in the data set,
holding something in the hand.

\section{Conclusion}

It is important that you write for the SIGCHI audience.  Please read
previous years' Proceedings to understand the writing style and
conventions that successful authors have used.  It is particularly
important that you state clearly what you have done, not merely what
you plan to do, and explain how your work is different from previously
published work, i.e., what is the unique contribution that your work
makes to the field?  Please consider what the reader will learn from
your submission, and how they will find your work useful.  If you
write with these questions in mind, your work is more likely to be
successful, both in being accepted into the Conference, and in
influencing the work of our field.

% Balancing columns in a ref list is a bit of a pain because you
% either use a hack like flushend or balance, or manually insert
% a column break.  http://www.tex.ac.uk/cgi-bin/texfaq2html?label=balance
% multicols doesn't work because we're already in two-column mode,
% and flushend isn't awesome, so I choose balance.  See this
% for more info: http://cs.brown.edu/system/software/latex/doc/balance.pdf
%
% Note that in a perfect world balance wants to be in the first
% column of the last page.
%
% If balance doesn't work for you, you can remove that and
% hard-code a column break into the bbl file right before you
% submit:
%
% http://stackoverflow.com/questions/2149854/how-to-manually-equalize-columns-
% in-an-ieee-paper-if-using-bibtex
%
% Or, just remove \balance and give up on balancing the last page.
%
\balance

% If you want to use smaller typesetting for the reference list,
% uncomment the following line:
% \small
\bibliographystyle{acm-sigchi}
\bibliography{gesture}
\end{document}
